# AI Chat Application Configuration

[app]
title = "AI Chat"
theme = "dark"                    # "dark" | "light" | "system"
default_model = "ollama-mistral"  # Must match a model key below

[documents]
default_directory = "~/Documents/AI-Exports"
filename_template = "{title}_{timestamp}.md"
include_metadata = true           # Include provenance in exported docs

[logging]
level = "INFO"                     # DEBUG | INFO | WARNING | ERROR | CRITICAL
file = ""                          # Optional: path to log file (empty = console only)
format = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"

[storage]
enabled = true                     # Enable conversation persistence
data_directory = "./data"          # SQLite database and attachments location

# =============================================================================
# AI Agents - Personas with instructions and optional knowledge sources
# =============================================================================

# Default agent (no special instructions) - auto-created if not present
[agents.default]
name = "Regular Chat"
description = "Standard conversation without specialized instructions"
instructions = ""
icon = ""

# Python development expert
[agents.python-expert]
name = "Python Expert"
description = "Specialized in Python development and best practices"
icon = ""
instructions = """
You are an expert Python developer with deep knowledge of:
- Modern Python (3.10+) features and idioms
- Type hints and static analysis (mypy, pyright)
- Testing with pytest
- Async programming with asyncio
- Package management with pip, poetry, and uv

Always provide Pythonic solutions following PEP 8 style guidelines.
Include type hints in all code examples.
Suggest modern alternatives when relevant.
"""

[[agents.python-expert.knowledge_sources]]
name = "Python 3.12 What's New"
url = "https://docs.python.org/3/whatsnew/3.12.html"
keywords = ["python 3.12", "new features", "pattern matching", "f-string"]
topics = ["python", "version", "features"]
cache_ttl_hours = 168

[[agents.python-expert.knowledge_sources]]
name = "PEP 8 Style Guide"
url = "https://peps.python.org/pep-0008/"
keywords = ["style", "pep8", "formatting", "conventions", "naming"]
topics = ["python", "style", "formatting"]
cache_ttl_hours = 720

# Code reviewer agent
[agents.code-reviewer]
name = "Code Reviewer"
description = "Reviews code for quality, security, and best practices"
icon = ""
instructions = """
You are an experienced code reviewer. When reviewing code:

1. **Security**: Check for vulnerabilities (injection, XSS, auth issues)
2. **Performance**: Identify inefficiencies and suggest optimizations
3. **Maintainability**: Assess readability, naming, and structure
4. **Best Practices**: Ensure the code follows language/framework conventions
5. **Testing**: Suggest test cases for critical paths

Be constructive and specific. Explain why something is an issue and how to fix it.
Prioritize issues by severity: Critical > Major > Minor > Nitpick.
"""

# =============================================================================
# AWS Bedrock Models
# =============================================================================
[models.bedrock-opus]
provider = "bedrock"
name = "Claude Opus 4.5"
model_id = "us.anthropic.claude-opus-4-5-20251101-v1:0"
region = "us-east-1"
supports_images = true
supports_documents = true
supports_reasoning = true
max_tokens = 8192
temperature = 0.7

[models.bedrock-sonnet]
provider = "bedrock"
name = "Claude Sonnet 4.5"
model_id = "us.anthropic.claude-sonnet-4-5-20250929-v1:0"
region = "us-east-1"
supports_images = true
supports_documents = true
supports_reasoning = true
max_tokens = 8192
temperature = 0.7

[models.bedrock-haiku]
provider = "bedrock"
name = "Claude Haiku 4.5"
model_id = "us.anthropic.claude-haiku-4-5-20251001-v1:0"
region = "us-east-1"
supports_images = true
supports_documents = true
supports_reasoning = false
max_tokens = 8192
temperature = 0.7

# =============================================================================
# Local OpenAI-Compatible Models
# =============================================================================
[models.ollama-mistral]
provider = "openai_compatible"
name = "Mistral (Ollama)"
base_url = "http://localhost:11434/v1"  # Ollama OpenAI-compatible endpoint
model = "mistral"
api_key = "ollama"
supports_images = false
supports_documents = false
supports_reasoning = false
max_tokens = 4096
temperature = 0.7

[models.local-llama]
provider = "openai_compatible"
name = "Llama 3.2 (Local)"
base_url = "http://localhost:1234/v1"   # LM Studio default
model = "llama-3.2-8b"
api_key = "lm-studio"                    # Often ignored by local servers
supports_images = false
supports_documents = false
supports_reasoning = false
max_tokens = 4096
temperature = 0.7

[models.local-qwen-coder]
provider = "openai_compatible"
name = "Qwen 2.5 Coder (llama.cpp)"
base_url = "http://localhost:8080/v1"   # llama.cpp server default
model = "qwen2.5-coder-32b"
api_key = "not-needed"
supports_images = false
supports_documents = false
supports_reasoning = true
max_tokens = 8192

[models.local-vision]
provider = "openai_compatible"
name = "LLaVA Vision (Local)"
base_url = "http://localhost:1234/v1"
model = "llava-v1.6"
api_key = "lm-studio"
supports_images = true
supports_documents = false
supports_reasoning = false
max_tokens = 4096
